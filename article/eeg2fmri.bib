
@article{n_functional_2015,
	title = {Functional {Neuroimaging}: {Fundamental} {Principles} and {Clinical} {Applications}.},
	volume = {28},
	issn = {1971-4009, 2385-1996},
	shorttitle = {Functional {Neuroimaging}},
	url = {https://europepmc.org/article/PMC/4757157},
	doi = {10.1177/1971400915576311},
	abstract = {Europe PMC is an archive of life sciences journal literature., Functional Neuroimaging: Fundamental Principles and Clinical Applications.},
	language = {English},
	number = {2},
	urldate = {2021-05-03},
	journal = {The Neuroradiology Journal},
	author = {N, Khanna and W, Altmeyer and J, Zhuo and A, Steven},
	month = apr,
	year = {2015},
	pmid = {25963153},
	pages = {87--96},
	file = {Snapshot:/home/paubric/Zotero/storage/SWEAJFVE/4757157.html:text/html},
}


@article{lample_phrase-based_2018,
	title = {Phrase-{Based} \& {Neural} {Unsupervised} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1804.07755},
	abstract = {Machine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of parallel sentences, which hinders their applicability to the majority of language pairs. This work investigates how to learn to translate when having access to only large monolingual corpora in each language. We propose two model variants, a neural and a phrase-based model. Both versions leverage a careful initialization of the parameters, the denoising effect of language models and automatic generation of parallel data by iterative back-translation. These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters. On the widely used WMT'14 English-French and WMT'16 German-English benchmarks, our models respectively obtain 28.1 and 25.2 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points. On low-resource languages like English-Urdu and English-Romanian, our methods achieve even better results than semi-supervised and supervised approaches leveraging the paucity of available bitexts. Our code for NMT and PBSMT is publicly available.},
	urldate = {2021-05-04},
	journal = {arXiv:1804.07755 [cs]},
	author = {Lample, Guillaume and Ott, Myle and Conneau, Alexis and Denoyer, Ludovic and Ranzato, Marc'Aurelio},
	month = aug,
	year = {2018},
	note = {arXiv: 1804.07755},
	keywords = {Computer Science - Computation and Language},
	file = {Lample et al_2018_Phrase-Based & Neural Unsupervised Machine Translation.pdf:/home/paubric/Zotero/storage/VRD696GB/Lample et al_2018_Phrase-Based & Neural Unsupervised Machine Translation.pdf:application/pdf;arXiv.org Snapshot:/home/paubric/Zotero/storage/U2GFSTKQ/1804.html:text/html},
}

@article{huster_methods_2012,
	title = {Methods for {Simultaneous} {EEG}-{fMRI}: {An} {Introductory} {Review}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/326053-08\$15.00/0},
	issn = {0270-6474, 1529-2401},
	shorttitle = {Methods for {Simultaneous} {EEG}-{fMRI}},
	url = {https://www.jneurosci.org/content/32/18/6053},
	doi = {10.1523/JNEUROSCI.0447-12.2012},
	abstract = {The simultaneous recording and analysis of electroencephalography (EEG) and fMRI data in human systems, cognitive and clinical neurosciences is rapidly evolving and has received substantial attention. The significance of multimodal brain imaging is documented by a steadily increasing number of laboratories now using simultaneous EEG-fMRI aiming to achieve both high temporal and spatial resolution of human brain function. Due to recent developments in technical and algorithmic instrumentation, the rate-limiting step in multimodal studies has shifted from data acquisition to analytic aspects. Here, we introduce and compare different methods for data integration and identify the benefits that come with each approach, guiding the reader toward an understanding and informed selection of the integration approach most suitable for addressing a particular research question.},
	language = {en},
	number = {18},
	urldate = {2021-05-03},
	journal = {Journal of Neuroscience},
	author = {Huster, René J. and Debener, Stefan and Eichele, Tom and Herrmann, Christoph S.},
	month = may,
	year = {2012},
	pmid = {22553012},
	note = {Publisher: Society for Neuroscience
Section: Toolbox},
	pages = {6053--6060},
	file = {Huster et al_2012_Methods for Simultaneous EEG-fMRI.pdf:/home/paubric/Zotero/storage/9KEWBUHN/Huster et al_2012_Methods for Simultaneous EEG-fMRI.pdf:application/pdf;Snapshot:/home/paubric/Zotero/storage/FFNRLIZ6/6053.html:text/html},
}

@inproceedings{zhuang_fmri_2019,
	title = {{FMRI} {Data} {Augmentation} {Via} {Synthesis}},
	doi = {10.1109/ISBI.2019.8759585},
	abstract = {We present an empirical evaluation of fMRI data augmentation via synthesis. For synthesis we use generative models trained on real neuroimaging data to produce novel task-dependent functional brain images. Analyzed generative models include classic approaches such as the Gaussian mixture model (GMM), and modern implicit generative models such as the generative adversarial network (GAN) and the variational autoencoder (VAE). In particular, the proposed GAN and VAE models utilize 3-dimensional convolutions, which enables modeling of high-dimensional brain image tensors with structured spatial correlations. The synthesized datasets are then used to augment classifiers designed to predict cognitive and behavioural outcomes. Our results suggest that the proposed models are able to generate high-quality synthetic brain images which are diverse and task-dependent. Perhaps most importantly, the performance improvements of data augmentation via synthesis are shown to be complementary to the choice of the predictive model. Thus, our results suggest that data augmentation via synthesis is a promising approach to address the limited availability of fMRI data, and to improve the quality of predictive fMRI models.},
	booktitle = {2019 {IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2019)},
	author = {Zhuang, Peiye and Schwing, Alexander G. and Koyejo, Oluwasanmi},
	month = apr,
	year = {2019},
	note = {ISSN: 1945-8452},
	keywords = {Brain modeling, Data models, fMRI generation, Functional magnetic resonance imaging, Gallium nitride, GANs, GMMs, Support vector machines, Three-dimensional displays, VAEs},
	pages = {1783--1787},
	file = {Zhuang et al_2019_FMRI Data Augmentation Via Synthesis.pdf:/home/paubric/Zotero/storage/4H7ZRIMV/Zhuang et al_2019_FMRI Data Augmentation Via Synthesis.pdf:application/pdf;IEEE Xplore Abstract Record:/home/paubric/Zotero/storage/Y8FJACII/8759585.html:text/html},
}

@article{calhas_eeg_2020,
	title = {{EEG} to {fMRI} {Synthesis}: {Is} {Deep} {Learning} a candidate?},
	shorttitle = {{EEG} to {fMRI} {Synthesis}},
	url = {http://arxiv.org/abs/2009.14133},
	abstract = {Advances on signal, image and video generation underly major breakthroughs on generative medical imaging tasks, including Brain Image Synthesis. Still, the extent to which functional Magnetic Ressonance Imaging (fMRI) can be mapped from the brain electrophysiology remains largely unexplored. This work provides the ﬁrst comprehensive view on how to use state-of-the-art principles from Neural Processing to synthesize fMRI data from electroencephalographic (EEG) data. Given the distinct spatiotemporal nature of haemodynamic and electrophysiological signals, this problem is formulated as the task of learning a mapping function between multivariate time series with highly dissimilar structures. A comparison of state-of-the-art synthesis approaches, including Autoencoders, Generative Adversarial Networks and Pairwise Learning, is undertaken. Results highlight the feasibility of EEG to fMRI brain image mappings, pinpointing the role of current advances in Machine Learning and showing the relevance of upcoming contributions to further improve performance. EEG to fMRI synthesis offers a way to enhance and augment brain image data, and guarantee access to more affordable, portable and long-lasting protocols of brain activity monitoring. The code used in this manuscript is available in Github and the datasets are open source.},
	language = {en},
	urldate = {2021-05-03},
	journal = {arXiv:2009.14133 [cs, stat]},
	author = {Calhas, David and Henriques, Rui},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.14133},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Calhas and Henriques - 2020 - EEG to fMRI Synthesis Is Deep Learning a candidat.pdf:/home/paubric/Zotero/storage/BEMCFC5V/Calhas and Henriques - 2020 - EEG to fMRI Synthesis Is Deep Learning a candidat.pdf:application/pdf},
}

@article{yi_generative_2019,
	title = {Generative adversarial network in medical imaging: {A} review},
	volume = {58},
	issn = {1361-8415},
	shorttitle = {Generative adversarial network in medical imaging},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841518308430},
	doi = {10.1016/j.media.2019.101552},
	abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
	language = {en},
	urldate = {2021-05-03},
	journal = {Medical Image Analysis},
	author = {Yi, Xin and Walia, Ekta and Babyn, Paul},
	month = dec,
	year = {2019},
	keywords = {Deep learning, Generative adversarial network, Generative model, Medical imaging, Review},
	pages = {101552},
	file = {ScienceDirect Snapshot:/home/paubric/Zotero/storage/49Q7A5RX/S1361841518308430.html:text/html;Yi et al_2019_Generative adversarial network in medical imaging.pdf:/home/paubric/Zotero/storage/G3RFWW6A/Yi et al_2019_Generative adversarial network in medical imaging.pdf:application/pdf},
}

@article{stahlberg_neural_2020,
	title = {Neural {Machine} {Translation}: {A} {Review}},
	volume = {69},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	shorttitle = {Neural {Machine} {Translation}},
	url = {https://jair.org/index.php/jair/article/view/12007},
	doi = {10.1613/jair.1.12007},
	language = {en},
	urldate = {2021-05-03},
	journal = {Journal of Artificial Intelligence Research},
	author = {Stahlberg, Felix},
	month = oct,
	year = {2020},
	keywords = {machine translation, natural language, neural networks},
	pages = {343--418},
	file = {Stahlberg_2020_Neural Machine Translation.pdf:/home/paubric/Zotero/storage/56ZBX975/Stahlberg_2020_Neural Machine Translation.pdf:application/pdf;Snapshot:/home/paubric/Zotero/storage/QRXCKZY4/12007.html:text/html},
}

@article{zhang_neural_2020,
	title = {Neural machine translation: {Challenges}, progress and future},
	volume = {63},
	issn = {1674-7321, 1869-1900},
	shorttitle = {Neural machine translation},
	url = {http://link.springer.com/10.1007/s11431-020-1632-x},
	doi = {10.1007/s11431-020-1632-x},
	language = {en},
	number = {10},
	urldate = {2021-05-03},
	journal = {Science China Technological Sciences},
	author = {Zhang, JiaJun and Zong, ChengQing},
	month = oct,
	year = {2020},
	pages = {2028--2050},
	file = {Zhang and Zong - 2020 - Neural machine translation Challenges, progress a.pdf:/home/paubric/Zotero/storage/HJEEF2BX/Zhang and Zong - 2020 - Neural machine translation Challenges, progress a.pdf:application/pdf},
}

@article{ostwald_eeg-fmri_2009,
	series = {Organization for {Human} {Brain} {Mapping} 2009 {Annual} {Meeting}},
	title = {{EEG}-{fMRI} signal integration: {An} information theoretic framework},
	volume = {47},
	issn = {1053-8119},
	shorttitle = {{EEG}-{fMRI} signal integration},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811909708705},
	doi = {10.1016/S1053-8119(09)70870-5},
	language = {en},
	urldate = {2021-05-03},
	journal = {NeuroImage},
	author = {Ostwald, D. and Porcaro, C. and Bagshaw, A. P.},
	month = jul,
	year = {2009},
	pages = {S101},
	file = {Ostwald et al_2009_EEG-fMRI signal integration.pdf:/home/paubric/Zotero/storage/Y45TUIMD/Ostwald et al_2009_EEG-fMRI signal integration.pdf:application/pdf;ScienceDirect Snapshot:/home/paubric/Zotero/storage/45F4BMIH/S1053811909708705.html:text/html},
}

@misc{noauthor_auditory_nodate,
	title = {Auditory and {Visual} {Oddball} {EEG}-{fMRI}},
	url = {https://legacy.openfmri.org/dataset/ds000116/},
	urldate = {2021-05-03},
	file = {Auditory and Visual Oddball EEG-fMRI:/home/paubric/Zotero/storage/8EMPP5AJ/ds000116.html:text/html},
}

@article{noauthor_functional_1993,
	title = {Functional brain mapping by blood oxygenation level-dependent contrast magnetic resonance imaging. {A} comparison of signal characteristics with a biophysical model},
	volume = {64},
	issn = {0006-3495},
	url = {http://www.sciencedirect.com/science/article/pii/S0006349593814413},
	doi = {10.1016/S0006-3495(93)81441-3},
	abstract = {It recently has been demonstrated that magnetic resonance imaging can be used to map changes in brain hemodynamics produced by human mental operations…},
	language = {en},
	number = {3},
	urldate = {2021-05-03},
	journal = {Biophysical Journal},
	month = mar,
	year = {1993},
	note = {Publisher: Cell Press},
	pages = {803--812},
	file = {_1993_Functional brain mapping by blood oxygenation level-dependent contrast magnetic.pdf:/home/paubric/Zotero/storage/9KU4K98E/_1993_Functional brain mapping by blood oxygenation level-dependent contrast magnetic.pdf:application/pdf;Snapshot:/home/paubric/Zotero/storage/PWZ8VFUD/S0006349593814413.html:text/html},
}

@article{bromley_signature_nodate,
	title = {Signature {Verification} using a "{Siamese}" {Time} {Delay} {Neural} {Network}},
	abstract = {This paper describes an algorithm for verification of signatures written on a pen-input tablet. The algorithm is based on a novel, artificial neural network, called a "Siamese" neural network. This network consists of two identical sub-networks joined at their outputs. During training the two sub-networks extract features from two signatures, while the joining neuron measures the distance between the two feature vectors. Verification consists of comparing an extracted feature vector {\textasciitilde}ith a stored feature vector for the signer. Signatures closer to this stored representation than a chosen threshold are accepted, all other signatures are rejected as forgeries.},
	language = {en},
	author = {Bromley, Jane and Guyon, Isabelle and LeCun, Yann and Säckinger, Eduard and Shah, Roopak},
	pages = {8},
	file = {Bromley et al. - Signature Verification using a Siamese Time Dela.pdf:/home/paubric/Zotero/storage/W46N27NQ/Bromley et al. - Signature Verification using a Siamese Time Dela.pdf:application/pdf},
}

@article{dosovitskiy_image_2020,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	language = {en},
	urldate = {2021-05-03},
	journal = {arXiv:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.11929},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Dosovitskiy et al. - 2020 - An Image is Worth 16x16 Words Transformers for Im.pdf:/home/paubric/Zotero/storage/2NMPZS6U/Dosovitskiy et al. - 2020 - An Image is Worth 16x16 Words Transformers for Im.pdf:application/pdf},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2021-05-03},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Vaswani et al_2017_Attention Is All You Need.pdf:/home/paubric/Zotero/storage/ZTEU8NGV/Vaswani et al_2017_Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/home/paubric/Zotero/storage/4U9SCI6J/1706.html:text/html},
}
