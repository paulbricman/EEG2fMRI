\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{authblk}

\title{EEG2fMRI: Cross-Modal Synthesis for Functional Neuroimaging}
\author{Paul Bricman}
\author{Jelmer Borst}
\affil{University of Groningen}
\date{July 2021}

\begin{document}

\maketitle

\section{Introduction}

Neural activity is central to investigating cognition. In cognitive neuroscience, it has been employed to study the neural correlates of numerous cognitive functions, such as perception, attention, and memory. In cognitive modelling, neural activity has been used to inform the development of a wide range of cognitive architectures and models. In clinical neuroscience, it has been employed for investigating, diagnosing, and ameliorating a wide range of neurological conditions. 

The increased relevance of neural activity in cognitive science prompted the development of a large number of functional neuroimaging techniques. These techniques can be effectively described in terms of spatial resolution, temporal resolution (sampling rate), and portability. The most widely used functional neuroimaging techniques are EEG and fMRI. EEG scanners consist of arrays of electrodes placed directly on the user's scalp. They are extremely portable and have high temporal resolution. However, such scanners can only detect neural activity after first being filtered by the skull, leading to a major decrease in spatial resolution. Conversely, fMRI is based on electromagnetic waves which easily penetrate the skull. Therefore, it has high spatial resolution, but is lacking in most other aspects. Compared to EEG, it is hundreds of times more expensive and thousands of times slower. Moreover, it is virtually unmovable by its user.

Given the lack of techniques which individually exhibit high overall performance, there have been numerous attempts to integrate their complementary qualities by using multiple techniques simultaneously. EEG-informed fMRI, fMRI-informed EEG, and neurogenerative modelling are all methods of integrating data from simultaneous EEG and fMRI recordings. However, these methods require extensive access to multiple techniques and are limited to niched applications.

Besides multi-modal functional neuroimaging, investigators have also proposed uni-modal synthesis as a method of augmenting neuroimaging techniques. This consists of conditionally synthetizing novel data based on previous data collected through the same modality. This method has been found to increase performance in downstream classifiers based on fMRI data.

In addition to uni-modal synthesis, investigators have also proposed cross-modal synthesis for augmenting neuroimaging techniques. This consists of reconstructing data collected through a target modality based on data collected through a distinct source modality, by exploiting the inherent relation between them. In a setting where both source and target modalities are available, this task might have limited utility. However, the value of cross-modal synthesis comes from settings where only one modality is available. In such settings, existing data can be used to approximate data collected through an unavailable modality. Unfortunately, this approach has largely been used for augmenting structural neuroimaging, with limited analogous efforts for functional neuroimaging.

Despite the major demand for high-performance functional neuroimaging and the success of cross-modal synthesis for structural neuroimaging, limited attention has been given to cross-modal synthesis for functional neuroimaging. The purpose of the current work is to formalize and explore the feasibility of this method. This comes as a natural extension to the growing collection of functional neuroimaging augmentation methods.

\section{Task}

The task of modelling the relation between two functional neuroimaging modalities can be addressed through at least three different approaches. This decision is mainly based on data availablility.

First, if simultaneous multi-modal recordings are available, supervised learning can be employed to model the mapping between the two domains based on paired samples. Unfortunately, the constraint of physical compatibility greatly restricts the pairs of modalities which can be investigated. For instance, MR-compatible EEG scanners have to be manufactured with special materials, in order to avoid physical injury during EEG-fMRI operation. Fortunately, the development of multi-modal methods of data integration has highlighted multiple candidate pairs of modalities for simultaneous recording.

Second, if simultaneous multi-modal recordings are not available, but separate recordings of similar mental states with different modalities are available (i.e. two separate recording sessions based on the same task but using different techniques), semi-supervised learning can be used to model the mapping through a task-related signal. This is analogous to the task of machine translation, which is often based on sample pairing through a cross-lingual signal.

Third, if the quantitiy of such recordings is limited, unsupervised learning can be used to learn the mapping by aligning latent spaces associated with the two modalities. This is analogous to machine translation where no paired multilingual corpora exist.

The following sections focus on supervised cross-modal synthesis, as the setup it requires is the most straight-forward.

\section{EEG-fMRI}

The suitability of EEG-fMRI as a candidate pair for cross-modal image synthesis is supported by the established practices of multi-modal neuroimaging using EEG-fMRI. These practices are the result of physical compatibility and the presence of complementary qualities.

Not only are EEG and fMRI compatible and complementary, but their results are also strongly correlated. The correlation occurs because both techniques can be used to record the same neural activity, albeit in different ways.

Model architecture: convolutional, residual

Evaluation: mse, psnr + mae, statistical test

\end{document}
